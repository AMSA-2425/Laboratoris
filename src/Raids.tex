\chapter{RAIDs (Redundant Array of Independent
Disks)}\label{raids-redundant-array-of-independent-disks}

Els sistemes RAID (Redundant Array of Independent Disks) són una solució
per a l'emmagatzematge de dades en entorns informàtics que requereixen
fiabilitat i eficiència. Aquesta tecnologia consisteix en utilitzar
diversos discs com si fossin un de sol, per aconseguir dos avantatges
principals: \textbf{redundància} i \textbf{rendiment}.

La \textbf{redundància} significa que les dades es guarden en més d'un
disc, de manera que si un d'ells falla, no es perd la informació. Això
s'anomena \emph{disc mirroring}. La redundància augmenta la fiabilitat
del sistema, ja que evita la pèrdua de dades en cas d'avaria.

El \textbf{rendiment} significa que les dades es distribueixen entre els
discs, de manera que es pot accedir a elles més ràpidament. Això
s'anomena \emph{disc striping}. El rendiment augmenta l'eficiència del
sistema, ja que redueix el temps de lectura i escriptura.

Per que un sistema RAID funcioni, cal disposar d'una controladora RAID,
que pot ser de dos tipus: per software o per hardware. La controladora
per software és un programa que s'executa al sistema operatiu i gestiona
els discs. La controladora per hardware és un dispositiu físic que
s'instal·la a la placa base i gestiona els discs de forma independent.
Avui en dia, la majoria de les plaques base incorporen una controladora
RAID per hardware, però aquesta opció és més habitual en entorns
empresarials que en domèstics.


\section{RAID Lineal}\label{raid-lineal}

El \textbf{RAID Lineal} és el més bàsic de tots els tipus de RAID. En aquest sistema, la informació es distribueix primer en un disc i després en l'altre, seguint un ordre seqüencial. Cada unitat d'informació es coneguda com a \textit{stripe}, i correspon a un bloc.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=\textwidth]{linear.png}
    \caption{Raid Lineal. /dev/md0: primer raid;  /dev/md1: segon raid, etc. El nombre màxim de raids ho determina el nucli.}
    \label{fig:raid-lineal}
\end{figure}

La figura \ref{fig:raid-lineal} mostra un exemple de RAID Lineal (\textbf{/dev/md0}) amb dos discs (\textbf{/dev/vda} i \textbf{/dev/vdb}). En aquest exemple s'han guardat els primers blocs (1 al 6) a la partició (\textbf{/dev/vda1}). Ara, s'ha d'assumir que la partició (\textbf{/dev/sda1}) es plena. Els següents blocs es guarden a la següent partició disponible (\textbf{/dev/vdb1}).

Tot i que el \textbf{RAID Lineal} és el més senzill de configurar, \textit{no proporciona cap avantatge significatiu en termes de redundància o rendiment de dades}.

\section{RAID 0 (Disc Striping)}\label{raid-0-disc-striping}

El \textbf{RAID 0} (veure Figura \ref{fig:raid0}) és una configuració que busca augmentar la velocitat del sistema. Aquesta millora es realitza distribuint alternativament els blocs de dades en dos o més discs. Aquesta distribució permet augmentar l'amplada de banda, ja que les dades es poden llegir i escriure de manera simultània, accelerant així el rendiment general del sistema.

No obstant això, el \emph{RAID 0} té un desavantatge significatiu: la falta de redundància. Si un dels discs durs falla, les dades afectades es perden permanentment, ja que no hi ha cap còpia de seguretat de les dades en cap altre disc.

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{raid0.png}
\caption{Raid 0}
\label{fig:raid0}
\end{figure}

La figura \ref{fig:raid0} mostra un exemple de RAID0 (\textbf{/dev/md0}) amb dos discs (\textbf{/dev/vda} i \textbf{/dev/vdb}). En aquest exemple s'han guardat els primers blocs (1 al 6) de forma alternada en cada disc. El següent bloc (9) es guardarà al disc (\textbf{/dev/vda}). En aquest exemple, els blocs senars es guarden al disc  (\textbf{/dev/vda}) i els parells al disc (\textbf{/dev/vdb}).

\begin{info}
La configuració RAID 0 no proporciona \textbf{redundància}, però millora significativament el \textbf{rendiment} del sistema.
\end{info}

\section{RAID 1 (Disc Mirroring)}\label{raid-1-disc-mirroring}

El \textbf{RAID 1} és una configuració que prioritza la seguretat de les dades. En aquesta configuració, cada bloc de dades es duplica exactament en dos discs diferents. Aquesta tècnica, coneguda com a \emph{mirroring}, permet que cada bloc de dades s'escriu simultàniament en dos discs diferents, creant així una còpia exacta de les dades en cada disc. 

Aquesta característica proporciona una gran tolerància a fallades: si un dels discs falla, l'altre disc pot continuar funcionant sense interrupció, ja que conté una còpia completa de totes les dades.

\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{raid1.png}
\caption{Raid 1}
\label{fig:raid1}
\end{figure}

La figura \ref{fig:raid1} mostra un exemple de RAID1 (\textbf{/dev/md0}) amb dos discs (\textbf{/dev/vda} i \textbf{/dev/vdb}). En aquest exemple s'han guardat els primers blocs (1 al 6) de forma idèntica en els dos discs. Això significa que si un dels discs falla, l'altre disc pot continuar funcionant sense interrupció, ja que conté una còpia completa de totes les dades.

En termes de rendiment, les lectures en un RAID 1 poden ser gairebé el doble de ràpides que en un sol disc, ja que les dades es poden llegir de qualsevol dels dos discs. No obstant, el rendiment d'escriptura és similar al d'un sol disc, ja que totes les dades han de ser escrites en ambdós discs.

\begin{info}
La configuració RAID 1 ofereix una alta \textbf{seguretat de les dades} gràcies a la seva redundància, però el rendiment d'escriptura és similar al d'un sol disc.
\end{info}

\section{RAID 2}\label{raid-2}

En el \textbf{RAID 2}, l'stripe és a nivell de bit. Aquesta configuració està dissenyada per proporcionar una codificació de la informació que permeti la detecció i correcció d'errors. En aquesta configuració, hi ha bits de dades i bits de paritat, que s'emmagatzemen en discs separats.

\begin{comment}
\begin{figure}[!htb]
  \centering
  \includegraphics[width=\textwidth]{raid2.png}
  \caption{Raid 2}
  \label{fig:raid2}
\end{figure}

La Figura~\ref{fig:raid2} mostra un exemple d'una configuració RAID 2 que implementa un codi Hamming(4,3), és a dir, 4 bits de dades i 3 bits de paritat. Aquesta configuració pot semblar poc pràctica en molts contextos, però ens proporciona una comprensió clara de com funciona la codificació de les dades i, en particular, la codificació de Hamming.

En aquesta configuració, cada disc \textbf{(vda, vdb, vdc i vdd)} conté blocs de dades que estan separats segons els seus bits. Per exemple, el bloc de dades 1 es divideix en quatre parts: \textit{(1a, 1b, 1c i 1d)}, que es distribueixen entre els quatre discs.

A més, hi ha tres discs addicionals  \textbf{(vde, vdf i vdg)} que contenen els bits de paritat (p1, p2 i p3). Aquests bits de paritat són essencials per a la detecció i correcció d'errors en la transmissió de dades.

Suposem que volem emmagatzemar la paraula ``1001''. Els bits que són potència de 2 (2$^k$, k=0,1, 2\ldots) són els bits de paritat, mentre que la resta de bits són dades.  Els bits de paritat es calculen com la \emph{XOR} dels bits que té associats. Els bits associats al bit de paritat 2$^k$ són els bits que la seva posició en la paraula conté la potència 2$^k$ (veure Taula~\ref{table:hamming43}). 

\begin{table}[!htb]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|}\cline{2-8}

\multicolumn{1}{c|}{}&1&2&3&4&5&6&7\\ \cline{2-8}
\multicolumn{1}{c|}{}&p$_1$&p$_2$&d$_1$&p$_3$&d$_2$&d$_3$&d$_4$\\ \hline
dades&&&1&&0&0&1\\ \hline
p$_1$&\textbf{1}&&0&&1&&0\\  \hline
p$_2$&&\textbf{0}&0&&&1&0\\  \hline
p$_3$&&&&\textbf{0}&1&1&0\\  \hline
paraula&1&0&0&0&1&1&0 \\  \hline
\end{tabular}
\caption{Hamming(7,4). Es pot veure les dades i com s'obté la paraula codificada. $p_1=d_1 \oplus d_2 \oplus d_4 \oplus d_5 \oplus d_7$. $p_2=d_1 \oplus d_3 \oplus d_4 \oplus d_6 \oplus d_7$. $p_3=d_2 \oplus d_3 \oplus d_4$.}
\label{table:hamming43}
\end{table}

\begin{info}
        La configuració RAID 2 està dissenyada per proporcionar una \textbf{alta tolerància a fallades} i \textbf{detecció i correcció d'errors}. No obstant això, aquesta configuració no és comuna en la pràctica, ja que altres configuracions de RAID poden proporcionar els mateixos avantatges amb menys complexitat.
\end{info}
\end{comment}

\subsection{Exemple. Hamming(7,4)}

A continuació presentem un exemple de codificació Hamming(7,4), que utilitza 7 bits de dades i 4 bits de paritat. Aquesta codificació té la capacitat de detectar i corregir un error. En altres paraules, pot identificar si un bit de dades ha canviat de ``1'' a ``0'', o viceversa.

\begin{mdframed}[linewidth=2pt,linecolor=teal]
Suposem que volem enviar la paraula ``0110101''. Els bits que són potència de 2 (2$^k$, k=0,1, 2\ldots) són els bits de paritat. La paraula codificada tindrà 11 bits, 7 de dades i 4 de paritat  (veure Taula~\ref{table:hamming74}). 
\end{mdframed}


\begin{table}[!htb]
        \centering
        \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}\cline{2-12}
        
        \multicolumn{1}{c|}{}&1&2&3&4&5&6&7&8&9&10&11\\ \cline{2-12}
        \multicolumn{1}{c|}{}&p$_1$&p$_2$&d$_1$&p$_3$&d$_2$&d$_3$&d$_4$&p$_4$&d$_5$&d$_6$&d$_7$\\ \hline
        dades&&&0&&1&1&0&&1&0&1\\ \hline
        p$_1$&\textbf{1}&&0&&1&&0&&1&&1\\  \hline
        p$_2$&&\textbf{0}&0&&&1&0&&&0&1\\  \hline
        p$_3$&&&&\textbf{0}&1&1&0&&&&\\  \hline
        p$_4$&&&&&&&&\textbf{0}&1&0&1 \\  \hline
        paraula&1&0&0&0&1&1&0&0&1&0&1 \\  \hline
        \end{tabular}
        \caption{Hamming(7,4). Es pot veure les dades i com s'obté la paraula codificada. $p_1=d_1 \oplus d_2 \oplus d_4 \oplus d_5 \oplus d_7$. $p_2=d_1 \oplus d_3 \oplus d_4 \oplus d_6 \oplus d_7$. $p_3=d_2 \oplus d_3 \oplus d_4$. $p_4=d_5 \oplus d_6 \oplus d_7$.}
        \label{table:hamming74}
        \end{table}


\begin{mdframed}[linewidth=2pt,linecolor=teal]
Suposem ara que rebem la paraula. Com es fa per comprovar que no hi ha hagut cap error? Es calculen els bits de comprovació, segons es fa a la Taula~\ref{Hamming74Noerror}.
\end{mdframed}


\begin{table}[!htb]
\footnotesize
\centering
\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|c|c|}\cline{2-13}
\multicolumn{1}{c|}{}&1&2&3&4&5&6&7&8&9&10&11&bit \\ \cline{2-12}
\multicolumn{1}{c|}{}&p$_1$&p$_2$&d$_1$&p$_3$&d$_2$&d$_3$&d$_4$&p$_4$&d$_5$&d$_6$&d$_7$&de\\ \cline{1-12}
paraula rebuda&1&0&0&0&1&1&0&0&1&0&1&comprovació\\ \hline
p$_1$&1&&0&&1&&0&&1&&1&0\\  \hline
p$_2$&&0&0&&&1&0&&&0&1&0\\  \hline
p$_3$&&&&0&1&1&0&&&&&0\\  \hline
p$_4$&&&&&&&&0&1&0&1&0 \\  \hline
\end{tabular}
\caption{Paraula rebuda sense errors. Es calcula el bit de comprovació per cada bit de paritat com la XOR del bit de paritat  i de tots els seus bits de dades associats. Bit de comprovació  de $p_1= p_1 \oplus d_1 \oplus d_2 \oplus d_4 \oplus d_5 \oplus d_7$. El bit de comprovació de $p_2 = p_2 \oplus d_1 \oplus d_3 \oplus d_4 \oplus d_6 \oplus d_7$. Bit de comprovació de $p_3= p_3 \oplus d_2 \oplus d_3 \oplus d_4$. Bit de comprovació de $p_4 = p_4 \oplus d_5 \oplus d_6 \oplus d_7$. Com que tots els bits de comprovació són 0, això vol dir que no hi ha hagut cap error.}
\label{Hamming74Noerror}
\end{table}


\begin{mdframed}[linewidth=2pt,linecolor=teal]
En canvi ara suposem que rebem una paraula amb 1 error a la dada d$_7$ (veure Taula~\ref{Hamming74error}).
\end{mdframed}

\begin{table}[!htb]
\footnotesize
\centering
\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|c|c|}\cline{2-13}
\multicolumn{1}{c|}{}&1&2&3&4&5&6&7&8&9&10&11&bit \\ \cline{2-12}
\multicolumn{1}{c|}{}&p$_1$&p$_2$&d$_1$&p$_3$&d$_2$&d$_3$&d$_4$&p$_4$&d$_5$&d$_6$&d$_7$&de\\ \cline{1-12}
paraula rebuda&1&0&0&0&1&1&0&0&1&0&\textbf{\color{blue}0}&comprovació\\ \hline
p$_1$&1&&0&&1&&0&&1&&0&1\\  \hline
p$_2$&&0&0&&&1&0&&&0&0&1\\  \hline
p$_3$&&&&0&1&1&0&&&&&0\\  \hline
p$_4$&&&&&&&&0&1&0&0&1 \\  \hline
\end{tabular}
\caption{Paraula rebuda amb 1 error. Com que en aquest cas no tots els bits de comprovació  són  0, això vol dir que hi ha hagut agun error.}
\label{Hamming74error}
\end{table}

Per trobar l'error, heu d'ordenar els bits de comprovació en ordre invers, tal com es mostra a la Taula~\ref{Hamming74error}. En aquest cas, l'error s'ha produït en el bit 11. 

\begin{table}[!htb]
\footnotesize
\centering
\begin{tabular}{|l|c|c|c|c|c|}\cline{2-5}
\multicolumn{1}{c|}{}&$p_4$&$p_3$&$p_2$&$p_1$&\multicolumn{1}{c}{} \\ \hline
binari&1&1&0&1&\\ \cline{1-6}
decimal&8&&2&1&= 11\\  \hline
\end{tabular}
\caption{L'error s'ha produït en el bit 11.}
\label{bitscomprovacio}
\end{table}


\section{RAID 4}\label{raid-4}

El \textbf{RAID 4} és una configuració de discs que busca augmentar la redundància i el rendiment. Aquesta configuració requereix un mínim de tres discs, on un d'ells s'utilitza exclusivament per a la paritat.

El \textbf{RAID 4}  és una configuració de discs que busca augmentar el rendiment i la tolerància a fallades. Aquesta configuració requereix un mínim de tres discs durs, on un d'ells s'utilitza exclusivament per a la paritat. %La millora en el rendiment de lectura del volum es calcula com la capacitat dels discs multiplicada pel nombre de discs menys un. Això es pot expressar com a: (\(D*(N-1)\). On \(D\) és la capacitat dels disc i \(N\) el nombre de discs utilitzats).

Un dels avantatges és la seva tolerància a fallades d'un disc (redundància). Si un disc falla, les dades es mantenen intactes i només cal substituir el disc defectuós. No obstant, si més d'un disc falla simultàniament, es perdrien dades.

La paritat és una operació XOR (o exclusiu) entre tots els bits de les dades en una mateixa posició de cada disc. Aquest valor de paritat s'emmagatzema en un altre disc del RAID. Aquesta tècnica permet que les dades es puguin recuperar en cas de fallada d'un disc.

\begin{info}
Té una tolerància a fallades d'un disc: si un disc falla, les dades es mantenen intactes i només cal canviar el disc defectuós. No obstant això, si fallen més d'un disc simultàniament, es perdrien dades.
\end{info}


\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{raid4.png}
\caption{Raid 4}
\label{fig:raid4}
\end{figure}

La figura \ref{fig:raid4} il·lustra un exemple de configuració RAID 4. En aquest exemple, el RAID 4, identificat com a \textbf{/dev/md0}, està format per cinc discs: \textbf{/dev/vda, /dev/vdb, /dev/vdc, /dev/vdd i /dev/vde}. En aquesta configuració RAID 4, els primers quatre discs \textbf{(/dev/vda, /dev/vdb, /dev/vdc, i /dev/vdd)} s'utilitzen per emmagatzemar les dades. El cinquè disc \textbf{(/dev/vde)} s'utilitza exclusivament per a la paritat.

\begin{info}
        La principal diferència entre RAID 3 i RAID 4 és la unitat de gestió de dades: en RAID 3 és un byte, mentre que en RAID 4 és un bloc.
\end{info}

Assumint l'exemple de la Figura~\ref{fig:raid4}, per calcular el valor de paritat, es realitza una operació XOR entre tots els bits de les dades en una mateixa posició de cada disc. Per exemple, si volem calcular el valor de paritat del disc 5:

\[P_{(Disc5)} = D_{(Disc1)} \oplus D_{(Disc2)} \oplus D_{(Disc3)}  \oplus D_{(Disc4)}\]

Aquest valor de paritat s'emmagatzema en un altre disc del RAID. Això permet que les dades es puguin recuperar en cas de fallada d'un disc. Suposem que el disc 2 falla, les seves dades podran ser reconstruides de
la següent manera:

\[D_{(Disc2)} = P_{(Disc5)} \oplus D_{(Disc1)} \oplus D_{(Disc2)} \oplus D_{(Disc3)}  \oplus D_{(Disc4)}\]

Observeu que podem reconstruir les dades del disc 2 a partir de les dades i la paritat emmagatzemades en els altres discs. Ara bé, si fallen més d'un disc simultàniament, es perdrien dades, ja que no es podria realitzar la seva reconstrucció.

\section{RAID 5}\label{raid-5}

La principal diferència entre el \textbf{RAID 4} i el \textbf{RAID 5} és la distribució de la paritat. En el \textbf{RAID 4}, la paritat es guarda en un disc dedicat, mentre que en el \textbf{RAID 5}, la paritat es distribueix entre tots els discs. Aquesta distribució millora el rendiment del sistema, ja que no hi ha un disc dedicat exclusivament per a la paritat. Aquesta distribució també millora el rendiment ja que elimina el coll  d'ampolla dels accessos a un únic disc de paritat. 


\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{raid5.png}
\caption{Raid 5}
\label{fig:raid5}
\end{figure}


El \textbf{RAID 5} ofereix un bon rendiment en termes de velocitat de lectura i escriptura. Això es deu al fet que es poden fer múltiples lectures simultànies dels diferents \emph{stripes}. No obstant, l'escriptura pot ser més lenta que en altres tipus de RAID degut al càlcul de la paritat. 

\begin{info}
El RAID 5 ofereix un bon equilibri entre rendiment i tolerància a fallades. Aquesta configuració és una opció popular per a molts sistemes d'emmagatzematge de dades.
\end{info}

La figura \ref{fig:raid5} il·lustra un exemple de configuració \textbf{RAID 5}. En aquesta configuració, la paritat es distribueix entre tots els discs, en lloc de ser emmagatzemada en un disc dedicat com en el \textbf{RAID 4}.



\section{RAID 10}\label{raid-10}
El \textbf{RAID 10}, també conegut com a RAID 1+0, és una combinació de \textbf{RAID 1} i \textbf{RAID 0}. Com el seu nom indica, aquesta configuració combina les millors característiques de \textbf{RAID 1} i \textbf{RAID 0} per proporcionar un rendiment superior i una alta tolerància a fallades.


La figura \ref{fig:raid10} il·lustra un exemple de configuració RAID 10. En aquesta configuració, les dades es dupliquen a nivell intern (una propietat aportada pel RAID 1) i es distribueixen entre múltiples discs a nivell extern (una propietat aportada pel RAID 0). En aquesta figura es pot veure com els 4 discs \textbf{vda, vdb, vdc i vdd} es distribueixen per configurar 2 RAIDs de nivell 1, i després aquestes RAIDs de nivell 1 es configuren com a RAID 0.

Aquesta combinació permet a RAID 10 oferir una alta tolerància a fallades gràcies a la duplicació de dades de RAID 1. Al mateix temps, aquesta configuració pot proporcionar un rendiment de lectura i escriptura superior gràcies a la distribució de dades de RAID 0. 


\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{raid10.png}
\caption{Raid 10}
\label{fig:raid10}
\end{figure}

\begin{info}
El RAID 10 ofereix una bona combinació de rendiment i redundància, fent-lo una opció popular per a aplicacions que requereixen altes velocitats de lectura i escriptura i una alta disponibilitat de dades. No obstant això, aquesta configuració requereix un mínim de quatre discs i ofereix una eficiència d'emmagatzematge del 50\%, ja que la meitat dels discs s'utilitzen per a la redundància.
\end{info}
        

\section{RAID 50}\label{raid-50}

El \textbf{RAID 50}, també conegut com a RAID 5+0, és una configuració de discs que combina les característiques del \textbf{RAID 5} i del \textbf{RAID 0}. Aquesta configuració proporciona un bon equilibri entre redundància i rendiment. En un sistema \textbf{RAID 50}, es creen múltiples arrays RAID 5, que després es combinen en un \textbf{RAID 0}. Això proporciona la redundància de paritat distribuïda del \textbf{RAID 5}, així com l'alta velocitat de lectura i escriptura del RAID 0. La configuració \textbf{RAID 50} requereix un mínim de sis discs durs. 

En la figura \ref{fig:raid50} s'il·lustra com es forma un \textbf{RAID 50}. En primer lloc, es creen dos RAIDs 5. Aquests propocionen la tolerància a fallades i la redundància de les dades. Després, aquests dos RAIDs 5 es combinen en un RAID 0. Això proporciona una alta velocitat de lectura i escriptura, ja que les dades es distribueixen entre els dos RAIDs 5.


\begin{figure}[!htb]
\centering
\includegraphics[width=\textwidth]{raid50.png}
\caption{Raid 50}
\label{fig:raid50}
\end{figure}

\begin{info}
Pot suportar la fallada d'un disc per cada RAID 5 sense perdre dades.
\end{info}

La principal diferència en termes de rendiment entre el \textbf{RAID 50} i el \textbf{RAID 5} és que el \textbf{RAID 50} ofereix una major velocitat de lectura i escriptura, ja que les dades es distribueixen entre múltiples arrays RAID 5. Si ho comparem amb el \textbf{RAID 10}; el \textbf{RAID 50} ofereix una major eficiència d'emmagatzematge. No obstant, el \textbf{RAID 50} té un temps de recuperació més llarg en cas de fallada d'un disc, ja que ha de reconstruir les dades de tots els discs de l'array \textbf{RAID 5} afectat i una velocitat d'escriptura més lenta que el \textbf{RAID 10}.


\section{Raids SW i Raids HW}

Els RAID software i hardware són dues maneres de configurar un sistema RAID. La principal diferència entre ambdues és la forma en què s'implementa el RAID. 

\begin{figure}[!htb]
     \centering
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=\textwidth]{SWRAID.png}
         \caption{Software raid.}
         \label{fig:SWRAID}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=\textwidth]{HWRAID.png}
         \caption{Hardware raid.}
         \label{fig:HWRAID}
     \end{subfigure}
        \caption{Tipus d'implementació de Raids.}
        \label{fig:implementacioRaids}
\end{figure}

Els RAID software són un tipus de RAID que s'implementa a nivell de sistema operatiu. Això significa que el RAID es configura i es gestiona utilitzant el programari del sistema operatiu. El RAID software és fàcil d'implementar i és compatible amb la majoria dels sistemes operatius. Totes les transaccions de les dades les realitza la CPU. Tal i com es pot veure en a Figura~\ref{fig:SWRAID}, els bits o blocs de dades es transmeten des de la Memòria Principal, on en la figura es denota amb ``Dades'' cap al Raid. Es possible que hi hagi registres intermitjos, on les dades s'hi emmagatzement temporalment, però tota les transaccions són realitzades pel processador (CPU).

En canvi, els RAID hardware són un tipus de RAID que s'implementa a nivell de hardware. Això significa que el RAID es configura i es gestiona utilitzant un controlador RAID dedicat. El RAID hardware és més ràpid i eficient que el RAID software, ja que les transaccions de les dades es realitzen pel controlador RAID i no per la CPU. Tal i com es pot veure en a Figura~\ref{fig:HWRAID}, els bits o blocs de dades es transmeten des de la Memòria Principal, on en la figura es denota amb ``Dades'' cap al Raid. Hi ha un hardware encarregat de fer les transferències entre el raid i la Memòria Principal, sense que hi intervingui la CPU. Mentre es fa la transferència, la CPU pot realitzar altres tasques, augmentant així enormement el rendiment del sistema.

\begin{info}
Els RAID software són més fàcils de configurar i gestionar, ja que es realitza a nivell de sistema operatiu. No obstant això, els RAID hardware ofereixen un millor rendiment i eficiència, ja que les transaccions de les dades es realitzen pel controlador RAID i no per la CPU.
\end{info}



\section{Instal·lació}\label{installacio-raids}

Per poder utilitzar els Raids software, cal instal·lar el paquet \texttt{mdadm}. Aquest paquet es troba disponible en la majoria de les distribucions Linux. Per instal·lar el paquet \texttt{mdadm}, en distribucions basades en Debian, segueix els passos següents:

\begin{enumerate}
\item Comprovem si el paquet està intal·lat:
\begin{lstlisting}[language=bash, numbers=none]
$ apt search mdadm
\end{lstlisting}

\item Instal·lem el paquet:
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# apt install mdadm -y
\end{lstlisting}
\end{enumerate}

\section{Operacions i Gestió de RAIDs}\label{operacions-i-gestió-de-raids}

\subsection{Creació d'un RAID}\label{creació-dun-raid}

Per crear un RAID, utilitza la comanda \texttt{mdadm --create}:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm 
    --create  
    --verbose /dev/[nom] 
    --level=[nivell] 
    --raid-devices=[Nº dispositius] [dispositius] 
\end{lstlisting}

On:

\begin{itemize}
    \item
    \textbf{create}: Crear un nou dispositiu md (RAID).
    \item
    \textbf{verbose}: Veure informació en temps real.
    \item
    \textbf{/dev/{[}{]}}: Nom i ubicació del RAID.
    \item
    \textbf{level={[}{]}}: Tipus de RAID (raid0, raid1, raid5, etc.) que es vol crear.
    \item
    \textbf{raid-devices = {[}{]}}: Especificar el nombre de dispositius o
    particions d'emmagatzematge que volem utilitzar en aquest dispositiu.
    \item
    \textbf{dispositius}: Especificar el nom i la ubicació dels
    dispositius.
\end{itemize}

\subsection{Ampliació d'un RAID}\label{ampliació-dun-raid}

És possible augmentar el nombre de discs en un RAID. Per exemple, imagina't un RAID 5 format inicialment per 3 discs físics. Al cap d'un any, decideixes comprar 2 discs extra. 

Amb l'ajuda de la comanda \texttt{mdadm --grow}, pots incorporar aquests discs al teu RAID existent i continuar utilitzant-lo sense problemes. La sintaxi de la comanda és la següent:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm 
    --grow /dev/[nom] 
    --raid-devices=[n_discs] 
\end{lstlisting}

Per exemple, si vols augmentar el nombre de discs en un RAID 5 format per 3 discs anomenat (/dev/md1) a quatre discs, la comanda seria:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm --grow /dev/md1 --raid-devices=4
\end{lstlisting}

\begin{mdframed}[linewidth=2pt,linecolor=red]
\textbf{Atenció!} Aquesta operació té algunes limitacions i requereix certa prudència i preparació, especialment si es tracta d'un RAID amb dades importants. Abans de fer aquest tipus de canvis, és \textbf{altament recomanable} fer una còpia de seguretat de les dades.
\end{mdframed}

\subsection{Substitució d'un disc defectuós}\label{substitució-dun-disc-defectuós}

Per substituir un disc defectuós en un RAID, es pot utilitzar la comanda \texttt{mdadm --manage --replace}. Aquesta comanda permet reemplaçar un disc defectuós amb un nou disc sense interrompre el funcionament del RAID. La sintaxi de la comanda és la següent on:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm --manage /dev/[nom] 
        --replace [disc_defectuos] 
        --with [nou_disc]
\end{lstlisting}

Per exemple, si es vol substituir un disc defectuós \textbf{/dev/sdb} en el RAID \textbf{/dev/md0} amb un nou disc \textbf{/dev/sdc}, la comanda seria:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm --manage /dev/md0 
        --replace /dev/sdb 
        --with /dev/sdc
\end{lstlisting}

\subsection{Eliminació d'un RAID}\label{eliminació-dun-raid}

Per eliminar un RAID, pots utilitzar la comanda \texttt{mdadm --stop}:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm --stop /dev/[nom] 
\end{lstlisting}

\begin{mdframed}[linewidth=2pt,linecolor=red]
\textbf{Atenció!}  Aquesta comanda no elimanarà les dades dels discs. Només desactivarà el RAID. Si vols eliminar completament el RAID i les dades, hauràs de formatejar els discs manualment. 
\end{mdframed}

\subsection{Obtenir informació}\label{obtenir-informació}

Per obtenir informació detallada sobre un RAID, utilitza la comanda \texttt{mdadm --detail}:

\begin{lstlisting}[language=bash, numbers=none]
$ mdadm --detail /dev/[nom]
\end{lstlisting}


\subsection{Afegir un disc de recanvi}\label{afegir-un-disc-de-recanvi}

 Un disc de recanvi és un disc que es manté inactiu fins que un dels discs actius falla. En cas de fallada d'un disc actiu, el disc de recanvi es posa en marxa automàticament.
 
 Per afegir un disc de recanvi a un RAID, utilitza la comanda \texttt{mdadm --manage --add}:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm --manage /dev/[nom] --add [disc_de_recanvi]
\end{lstlisting}

Per exemple, si vols afegir un disc de recanvi \textbf{/dev/sdd} al RAID
\textbf{/dev/md1}, la comanda seria:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm --manage /dev/md1 --add /dev/sdd
\end{lstlisting}

\subsection{Eliminar un disc}\label{eliminar-un-disc}

Per eliminar un disc d'un RAID, pots utilitzar la comanda \texttt{mdadm
--manage --remove}:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm --manage /dev/[nom] --remove [disc_a_eliminar]
\end{lstlisting}

\begin{mdframed}[linewidth=2pt,linecolor=teal]
\textbf{OBSERVACIÓ}: Aquesta comanda retirarà el disc del RAID,
redistribuint les dades altra vegada en els altres discs restants.
\end{mdframed}

\section{Exemple 1: Simulant un Entorn amb RAIDs}\label{simulant-un-entorn-amb-raids}

En aquest exemple es preten configurar un entorn utilitzant RAIDs per mostrar com es poden crear, gestionar i mantenir. Aquest exemple es basa en un entorn simulat, però els passos són aplicables a un entorn real. 

\subsection{Entorn de Treball}\label{entorn-de-treball}

Per configurar aquest entorn de treball, nessitem una màquina virtual amb un sistema operatiu Linux (en el nostre cas s'ha utilitzat \emph{Debian 12}) instal·lat en un disc principal (\textbf{vda}) i 4 discs virtuals addicionals (\textbf{vdb, vdc, vdd i vde}) de 1GB cadascun. Aquests discs virtuals addicionals seran utilitzats per crear els RAIDs. A més a més, utilitzarem el sistema de fitxers \emph{XFS} per formatejar els discs. Aquest sistema de fitxers no es troba instal·lat per defecte en Debian, per tant, caldrà instal·lar-lo. Per poder reproduir aquest exemple, necessiteu tenir una configuració inicial similar a la següent:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# lsblk
\end{lstlisting}

\begin{terminaloutput}
\footnotesize\begin{verbatim}
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
sr0     11:0    1 1024M  0 rom
vda    254:0    0   64G  0 disk
|-vda1 254:1    0  512M  0 part /boot/efi
|-vda2 254:2    0 62,5G  0 part /
|-vda3 254:3    0  976M  0 part [SWAP]
vdb    254:16   0    1G  0 disk
vdc    254:32   0    1G  0 disk
vdd    254:48   0    1G  0 disk
vde    254:64   0    1G  0 disk
\end{verbatim}
\end{terminaloutput}
  
\begin{warning}
Podeu adaptar aquest exemple a la vostra configuració. Podeu utilitzar particions en lloc de discs virtuals, canviar el nombre dels discs, etc.
\end{warning}

\subsection{Pas 1: Instal·lació del sistema de fitxers XFS}\label{pas-1-xfs}

Si utilitzeu versions de Linux basades en Red Hat, com CentOS o Fedora, el sistema de fitxers \emph{XFS} ja està instal·lat per defecte. No obstant això, si utilitzeu Debian o Ubuntu, caldrà instal·lar-lo. Per fer-ho, segueix els passos següents:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# apt update
# apt install xfsprogs -y
\end{lstlisting}

El sistema de fitxers \emph{XFS} ofereix diverses característiques atractives que el fan ideal per a entorns de servidor. Entre aquestes característiques es troben la capacitat de realitzar \textbf{snapshots}, i la possibilitat d'assignar \textbf{quotes} d'ús als usuaris, proporcionant un control més gran sobre l'ús dels recursos del sistema.

A diferència d'altres sistemes de fitxers, com ara \emph{ext4}, que estan més orientats a l'ús en sistemes personals, \emph{XFS} està dissenyat per mantenir un rendiment òptim en tot moment. Una de les seves principals avantatges és que no necessita ser desfragmentat. Això es deu al fet que \emph{XFS} utilitza un algoritme d'assignació d'espai que minimitza la fragmentació de fitxers, optimitzant així el rendiment del sistema de fitxers.

\subsection{Pas 2: Creació d'un RAID 0}\label{pas-2-creació-dun-raid-0}

En aquest exemple, crearem un RAID 0 utilitzant els discs virtuals \textbf{/dev/vdb} i \textbf{/dev/vdc}. Aquest RAID 0 es denominarà \textbf{/dev/md0}. Aquest RAID 0 es formatejarà amb el sistema de fitxers \emph{XFS}. Per fer-ho, segueix els passos següents:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm --create --verbose /dev/md0 --level=0  --chunk 256 --raid-devices=2 /dev/vdb /dev/vdc
\end{lstlisting}

\begin{terminaloutput}
\footnotesize\begin{verbatim}
mdadm: Defaulting to version 1.2 metadata
mdadm: array /dev/md0 started.
\end{verbatim}
\end{terminaloutput}

Per defecte, s'ha inicialitzat el RAID 0 amb un \textbf{chunk size} de 256K i una versió de metadades  \emph{1.2}. La mida del \textit{chunk} és la quantitat de dades que es llegeixen o escriuen en cada operació d'entrada/sortida. Mentres que la versió de metadades indica la versió del format de metadades utilitzat pel RAID. Aquest valor pot ser modificat mitjançant l'opció \texttt{--metadata}. Un cop creat el RAID 0, es pot comprovar el seu estat utilitzant la comanda \texttt{mdadm --detail}:

\begin{terminaloutput}
\footnotesize\begin{verbatim}
mdadm --detail /dev/md0
/dev/md0:
        Version : 1.2
        Raid Level : raid0
        Array Size : 2093056 (2044.00 MiB 2143.29 MB)
        Name : debian:0  (local to host debian)
        UUID : c3bdf605:bca6bbde:b85597c2:00428d9a
        Number   Major   Minor   RaidDevice State
        0     254       16        0      active sync   /dev/vdb
        1     254       32        1      active sync   /dev/vdc
\end{verbatim}
\end{terminaloutput}

S'ha simplificat la sortida per a una millor comprensió. En aquesta sortida, es pot veure que el RAID 0 \textbf{/dev/md0} està format per dos discs: \textbf{/dev/vdb} i \textbf{/dev/vdc}. Amb aquesta configuració, el RAID 0 tindrà una capacitat total de 2GB (1GB per disc).

Un cop inicialitzat el RAID 0, cal formatejar-lo amb el sistema de fitxers \emph{XFS}. Per fer-ho, utilitza la comanda \texttt{mkfs.xfs}:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mkfs.xfs /dev/md0
\end{lstlisting}

\begin{terminaloutput}
\footnotesize\begin{verbatim}
meta-data=/dev/md0        isize=512    agcount=8, agsize=65344 blks
        =                 sectsz=512   attr=2, projid32bit=1
        =                 crc=1        finobt=1, sparse=1, rmapbt=0
        =                 reflink=1    bigtime=1 inobtcount=1 nrext64=0
data    =                 bsize=4096   blocks=522752, imaxpct=25
        =                 sunit=64     swidth=128 blks
naming  =version 2        bsize=4096   ascii-ci=0, ftype=1
log     =internal log     bsize=4096   blocks=16384, version=2
        =                 sectsz=512   sunit=64 blks, lazy-count=1
realtime =none            extsz=4096   blocks=0, rtextents=0
Discarding blocks...Done.

\end{verbatim}
\end{terminaloutput}

Un cop formatat, el RAID 0 està llest per ser muntat. Per muntar el RAID 0, crea un directori de muntatge i utilitza la comanda \texttt{mount}:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mkdir /mnt/raid0
# mount /dev/md0 /mnt/raid0
\end{lstlisting}

El RAID 0 s'ha muntat de forma temporal al directori \textbf{/mnt/raid0}. Per comprovar que s'ha muntat correctament, utilitza la comanda \texttt{df -h}:

\begin{terminaloutput}
\footnotesize\begin{verbatim}
S. fitxers      Mida En ús Lliure  %Ús Muntat a
udev            1,9G     0   1,9G   0% /dev
tmpfs           393M  872K   392M   1% /run
/dev/vda2        62G  1,4G    57G   3% /
tmpfs           2,0G     0   2,0G   0% /dev/shm
tmpfs           5,0M     0   5,0M   0% /run/lock
/dev/vda1       512M  6,1M   506M   2% /boot/efi
tmpfs           393M     0   393M   0% /run/user/1000
/dev/md0        2,0G   47M   1,9G   3% /mnt/raid0
\end{verbatim}
\end{terminaloutput}

Noteu com el RAID 0 s'ha muntat correctament al directori \textbf{/mnt/raid0}. Té una capacitat de 2GB, amb 47MB utilitzats i 1.9GB lliures. Aquestes dades utilitzades són per les metadades del sistema de fitxers i altres metadades internes del RAID.

\subsection{Pas 3: Creació d'un RAID 1}\label{pas-3-creació-dun-raid-1}

En aquest exemple, crearem un RAID 1 utilitzant els discs virtuals \textbf{/dev/vdd} i \textbf{/dev/vde}. Aquest RAID 1 es denominarà \textbf{/dev/md1}. Els passos per crear un RAID 1 són similars als d'un RAID 0. El formatejarem amb el sistema de fitxers \emph{XFS} i el muntarem al directori \textbf{/mnt/raid1}. Per fer-ho, segueix els passos següents:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm --create --verbose /dev/md1 --level=1 --raid-devices=2 /dev/vdd /dev/vde
\end{lstlisting}

\begin{terminaloutput}
\footnotesize\begin{verbatim}
mdadm: Note: this array has metadata at the start and
        may not be suitable as a boot device.  If you plan to
        store '/boot' on this device please ensure that
        your boot-loader understands md/v1.x metadata, or use
        --metadata=0.90
mdadm: size set to 1046528K
Continue creating array? y
mdadm: Defaulting to version 1.2 metadata
mdadm: array /dev/md1 started.
\end{verbatim}
\end{terminaloutput}

Aquesta advertencia ens indica que les metadades estan configurades com a \textbf{md/v1.x}, i aquest tipus de metadades no és el més adequat per a un dispositiu d'arrencada (boot device). Aquest tipus de metadades poden no ser compatibles amb alguns carregadors d'arrencada (boot loaders). Si la nostra RAID fos per \textbf{/boot} llavors necessitariam \texttt{\$ mdadm --create --verbose /dev/md1 --level=1 --metadata=0.90 --raid-devices=2 /dev/vdd /dev/vde}. Però com no és el cas podem ometre aquest \textbf{warning}.


Un cop creat el RAID 1, cal formatejar-lo amb el sistema de fitxers \emph{XFS} i muntar-lo al directori \textit{/mnt/raid1}. Per fer-ho:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mkfs.xfs /dev/md1
# mkdir /mnt/raid1
# mount /dev/md1 /mnt/raid1
\end{lstlisting}

Podem realitzar les comprovacions pertinents amb la comanda \texttt{mdadm --detail} i \texttt{df -h} per assegurar-nos que el RAID 1 s'ha creat correctament i s'ha muntat al directori \textbf{/mnt/raid1}.

\begin{terminaloutput}
\footnotesize\begin{verbatim}
S. fitxers      Mida En ús Lliure  %Ús Muntat a
/dev/md0        2,0G   47M   1,9G   3% /mnt/raid0
/dev/md1        958M   39M   920M   5% /mnt/raid1
\end{verbatim}
\end{terminaloutput}

\begin{info}
Si analitzeu la sortida de la comanda \texttt{df -h}, observarem les diferents propietats del RAID 0 i del RAID 1. Per exemple, el RAID 0 té una capacitat de 2GB, mentre que el RAID 1 té una capacitat de 1GB. Això es deu al fet que el RAID 1 és un mirall (mirror) i les dades es dupliquen en tots dos discs. El RAID 1 perd la meitat de la capacitat total per garantir la redundància de les dades. Mentre que el RAID 0 té una capacitat total de 2GB, ja que les dades es distribueixen entre els dos discs.
\end{info}


\subsection{Pas 3: Utilitzant el RAID}\label{pas-3-utilitzant-la-raid}

%Per poder utiltizar el RAIDs, crearem alguns fitxers i directoris. A partir d'ara, el RAID 0 es comportarà com un disc dur normal. 

Utiltizarem la comanda \texttt{fallocate} que ens permet crear fitxers de la mida que li indiquem. En aquest cas, crearem 3 fitxers en el directori del  RAID 0 (\texttt{/mnt/raid0}), de 20MB cadascun:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# fallocate -l 20M /mnt/raid0/arxiu1.txt
# fallocate -l 20M /mnt/raid0/arxiu2.txt
# fallocate -l 20M /mnt/raid0/arxiu3.txt
\end{lstlisting}

Per comprovar que s'han creat els fitxers, utilitza la comanda \texttt{ls -lh /mnt/raid0}:

\begin{terminaloutput}
\footnotesize\begin{verbatim}
total 60M
-rw-r--r-- 1 root root 20M 15 d'abr.   11:43 arxiu1.txt
-rw-r--r-- 1 root root 20M 15 d'abr.   11:43 arxiu2.txt
-rw-r--r-- 1 root root 20M 15 d'abr.   11:43 arxiu3.txt
\end{verbatim}
\end{terminaloutput}

Un altra forma de revisar-ho pot ser amb \texttt{du -h /mnt/raid0}:

\begin{terminaloutput}
\footnotesize\begin{verbatim}
60M    /mnt/raid0
\end{verbatim}
\end{terminaloutput}

Ara crearem un fitxer de 100MB al RAID 1 utilitzant la comanda \texttt{dd}:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# dd if=/dev/zero of=/mnt/raid1/arxiu4.txt bs=1024 count=100k
\end{lstlisting}

\begin{terminaloutput}
\footnotesize\begin{verbatim}
102400+0 records in
102400+0 records out
104857600 bytes (105 MB, 100 MiB) copied, 0.107073 s, 980 MB/s
\end{verbatim}
\end{terminaloutput}

Per comprovar que s'ha creat el fitxer, utilitza la comanda \texttt{ls -lh /mnt/raid1}:

\begin{terminaloutput}
\footnotesize\begin{verbatim}
total 100M
-rw-r--r-- 1 root root 100M 15 d'abr.   11:43 arxiu4.txt
\end{verbatim}
\end{terminaloutput}

\subsection{Pas 4: Proves de Rendiment}\label{pas-4-proves-de-rendiment}

Una de les diferències principals entre el \textbf{RAID 0} i el \textbf{RAID 1} és el rendiment de les operacions de lectura i escriptura. En el cas del \textbf{RAID 0}, les operacions de lectura i escriptura són més ràpides, ja que les dades es distribueixen entre els dos discs. En canvi, en el cas del \textbf{RAID 1}, les operacions de lectura són ràpides, ja que es poden llegir les dades de qualsevol dels dos discs. Les escriptures però són més lentes, ja que les dades s'han de copiar en tots dos discs.

Per demostrar-ho utilitzarem \texttt{fio}, una eina de benchmarking de discs. Aquesta eina permet provar el rendiment dels discs durs i altres dispositius d'emmagatzematge. En aquest cas, utilitzarem \texttt{fio} per provar el rendiment del \textbf{RAID 0} i \textbf{RAID 1}. Per instal·lar \texttt{fio}, utilitzarem la comanda:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# apt install fio -y
\end{lstlisting}

Un cop instal·lat \texttt{fio}, realitzarem les nostres proves de rendiment basades en la lectura i escriptura de fitxers. En aquest punt, disenyarem un benchmark per provar el rendiment. Les comandes següents ens permeten crear dos benchmarks per a cada RAID: 

\begin{enumerate}
        \item \textbf{Escriptura}: Prova el rendiment de les operacions d'escriptura.
        \item \textbf{Lectura}: Prova el rendiment de les operacions de lectura.
\end{enumerate}

\begin{lstlisting}[language=bash, numbers=none]
# Test de rendiment del RAID 0 en operacions d'escriptura  
$ fio --name=write-raid1 --ioengine=libaio --iodepth=32 --rw=write --bs=4k --size=500M --numjobs=4 --runtime=120 --time_based --ramp_time=15 --group_reporting --filename=/dev/raid1 --output-format=json --output=/tmp/write-raid1.json
# Test de rendiment del RAID 1 en operacions d'escriptura       
$ fio --name=write-raid0 --ioengine=libaio --iodepth=32 --rw=write --bs=4k --size=500M --numjobs=4 --runtime=120 --time_based --ramp_time=15 --group_reporting --filename=/dev/raid0 --output-format=json --output=/tmp/write-raid0.json  
\end{lstlisting}

En aquestes proves, hem utilitzat un bloc de 4KB, que és una mida de bloc comuna en molts sistemes de fitxers i bases de dades. A més a més, hem utilitzat un tamany total de 500MB per a les proves, que és una mida suficient i bastant usual. Hem executat 4 treballs simultanis, que simulen l'escenari en què múltiples processos o fils estan llegint o escrivint en el disc al mateix temps. Això també pot ser comú en molts escenaris, com ara en un servidor web que atén múltiples peticions al mateix temps, o en una aplicació de processament de dades que utilitza múltiples fils per a accelerar el processament. 

\begin{lstlisting}[language=bash, numbers=none]
# Test de rendiment del RAID 1 en operacions de lectura
$ fio --name=read-raid1 --ioengine=libaio --iodepth=32 --rw=read --bs=4k --size=500M --numjobs=4 --runtime=120 --time_based --ramp_time=15 --group_reporting --filename=/dev/raid1 --output-format=json --output=/tmp/read-raid1.json
# Test de rendiment del RAID 0 en operacions de lectura              
$ fio --name=read-raid0 --ioengine=libaio --iodepth=32 --rw=read --bs=4k --size=500M --numjobs=4 --runtime=120 --time_based --ramp_time=15 --group_reporting --filename=/dev/raid0 --output-format=json --output=/tmp/read-raid0.json
\end{lstlisting}

Les operacions de lectura i escriptura són sequencials, la qual cosa significa que les dades es llegeixen o s'escriuen en blocs consecutius en el disc. Això pot ser més ràpid que les operacions aleatòries, ja que el cap de lectura/escriptura del disc pot moure's de manera contínua, en lloc d'haver de saltar a diferents ubicacions del disc. Finalment, hem utilitzat \textit{ramp\_time} de 15 segons. Això significa que les proves comencen lentament i augmenten la càrrega de treball de manera gradual fins a arribar al màxim al cap de 15 segons. Aquesta tècnica es fa servir per a assegurar que el sistema està en un estat estable abans de començar a recollir dades, de manera que els resultats de les proves siguin més fiables. Podeu modificar aquests paràmetres segons les vostres necessitats i escenaris d'ús que vulgueu provar.

Els resultats de les proves es guardaran en un fitxer JSON per a un anàlisi posterior. En aquest experiment ens centrarem en 4 variables principals per comparar el rendiment del RAID 0 i del RAID 1, en operacions de lectura (R) i escriptura (W):
\begin{itemize}
        \item \textbf{Bandwidth}: La velocitat de transferència de dades en bytes per segon.
        \item \textbf{IOPS}: El nombre d'operacions d'entrada/sortida per segon.
        \item \textbf{Latència}: El temps que triga el sistema a respondre a una petició d'entrada/sortida.
        \item \textbf{Total IO}: El nombre total d'operacions d'entrada/sortida.
\end{itemize}

\begin{table}[!htb]
\begin{tabular}{|l|l|r|r|r|r|}
\hline
Op. & RAID & \textbf{Bandwidth} (GB/s) & \textbf{IOPS} & \textbf{Latència} (µs) &\textbf{Total IO} (GB) \\
\hline
W &  0 & 10.58 & 2.65e+06 & 48.22 & 317.6 \\
W &  1 & 7.93 & 1.98e+06 & 64.40 & 238.0 \\
R &  0 & 18.76 & 4.69e+06 & 27.16 & 562.98 \\
R &  1 & 18.82 & 4.71e+06 & 27.08 & 564.6 \\
\hline
\end{tabular}
\caption{Resultats de les proves de rendiment del RAID 0 i del RAID 1.}
\label{table:raid-performance}
\end{table}

La Taula \ref{table:raid-performance} mostra un resum dels resultats obtinguts de les proves de rendiment del RAID 0 i del RAID 1. Aquests resultats corroboren les diferències de rendiment entre els dos tipus de RAID. En primer lloc, si ens centrem en el \textbf{Bandwidth}, podem observar un rendiment similar en les operacions de lectura amb unes velocitats de 18.76GB/s i 18.82GB/s respectivament. En canvi, el RAID 0 té un rendiment superior en les operacions d'escriptura amb una velocitat de 10.59GB/s, mentre que el RAID 1 té una velocitat de 7.93GB/s. Això es deu al fet que en el RAID 0 les dades es distribueixen entre els dos discs, mentre que en el RAID 1 les dades s'han de copiar en tots dos discs. En segon lloc, si analitzem les variables de Latency i IOPS observem un rendiment similar en les operacions de lectura, amb una latència de 27.16µs i 27.08µs respectivament. En canvi, en les operacions d'escriptura, el RAID 0 té una latència de 48.22µs i 64.40µs en el RAID 1. Finalment, en termes de Total IO, el RAID 0 té un rendiment superior amb 317.6GB en les operacions d'escriptura, mentre que el RAID 1 té un rendiment de 238.0GB.

Aquesta anàlisi demostra que el RAID 0 ofereix un rendiment superior en termes de velocitat d'escriptura, mentre que el RAID 1 proporciona una major seguretat de les dades a costa d'una velocitat d'escriptura més lenta


\subsection{Pas 4: Tolerància a fallades}\label{pas-4-tolerància-a-fallades}

En aquest apartat, analitzarem la tolerància a fallades dels RAIDs. Per fer-ho, simularem una fallada en un dels discs dels RAIDs i comprovarem com afecta a les dades. 

Si ens centrem en el RAID 1, veurem com una fallada en un dels discs no afecta a les dades, ja que les dades es dupliquen en tots dos discs. Això permet mantenir la disponibilitat de les dades en cas de fallada d'un disc.

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm --manage --set-faulty /dev/md1 /dev/vdd
\end{lstlisting}

\begin{terminaloutput}
\footnotesize\begin{verbatim}
mdadm: set /dev/vdd faulty in /dev/md1
\end{verbatim}
\end{terminaloutput}

Ara podem observar l'estat del RAID 1 amb la comanda \texttt{cat /proc/mdstat}:

\begin{terminaloutput}
\footnotesize\begin{verbatim}
Personalities : [raid0] [raid1]
md1 : active raid1 vde[1] vdd[0](F)
      1046528 blocks super 1.2 [2/1] [_U]
md0 : active raid0 vdc[1] vdb[0]
      2093056 blocks super 1.2 256k chunks  
unused devices: <none>
\end{verbatim}
\end{terminaloutput}

En aquesta sortida, podem veure que el disc \textbf{/dev/vdd} s'ha marcat com a fallit (F), mentre que el disc \textbf{/dev/vde} està actiu. Això significa que el RAID 1 encara està operatiu i les dades són accessibles. Per comprovar que les dades s'han mantingut intactes:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# ls -la /mnt/raid1
\end{lstlisting}

\begin{terminaloutput}
\footnotesize\begin{verbatim}
total 100M
drwxr-xr-x 2 root root  4096 Apr 15 11:43 .
drwxr-xr-x 3 root root    18 Apr 15 11:43 ..
-rw-r--r-- 1 root root 100M Apr 15 11:43 arxiu4.txt
\end{verbatim}
\end{terminaloutput}

Com es pot observar, les dades s'han mantingut intactes i són accessibles. Això demostra la capacitat del RAID 1 de mantenir la disponibilitat de les dades en cas de fallada d'un disc.

Si ens centrem en el RAID 0, veurem com una fallada en un dels discs pot provocar la pèrdua de totes les dades. Això es deu al fet que en el RAID 0 les dades es distribueixen entre els dos discs, i si un dels discs falla, es perden totes les dades. En aquest cas, no podem simular la fallada d'un disc amb la comanda \texttt{mdadm --manage --set-faulty}, ni tampoc traient el disc del RAID0 amb la comanda \texttt{mdadm --manage --remove}. Per tant, intentarem corrompre les dades del disc \textbf{/dev/vdc} per simular una fallada. Podem corrompre les dades del disc utilitzant la comanda hexdump:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# hexdump -C /dev/vdc | head -n 10
# umount /mnt/raid0
# mount /dev/md0 /mnt/raid0
\end{lstlisting}

\begin{terminaloutput}
\footnotesize\begin{verbatim}
mount: /mnt/raid0: can't read superblock on /dev/md0.
dmesg(1) may have more information after failed mount system call.
\end{verbatim}
\end{terminaloutput}

Si retornem al RAID 1, i tornem a marcar el disc \textbf{/dev/vdd} com a no fallit:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm --manage --re-add /dev/md1 /dev/vdd
\end{lstlisting}

\begin{info}
Si ara corrompeu les dades del disc \textbf{/dev/vde}, tal com hem fet amb el disc \textbf{/dev/vdc}, veureu que les dades s'han mantingut intactes i són accessibles. Això demostra la capacitat del RAID 1 de mantenir la disponibilitat de les dades en cas de fallada d'un disc.
\end{info}

A més a més, podem seguir utilitzant el RAID 1 amb un disc fallit, fins que substituïm el disc fallit per un de nou.

Per exemple, podem afegir un nou fitxer al RAID 1 amb un disc fallit:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
$ dd if=/dev/urandom of=/mnt/raid1/arxiu5.txt bs=1024 count=100k
\end{lstlisting}


\subsection{Pas 5: Disc de recanvi}\label{pas-5-disc-de-recanvi}

En aquest apartat, veurem com afegir un disc de recanvi a un RAID 1. Per fer-ho aturarem el RAID0, alliberarem els discs vdb i vdc, i els afegirem al RAID1 com a discs de recanvi.

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm --stop /dev/md0
# mkfs.xfs /dev/vdb
# mkfs.xfs /dev/vdc
# mdadm --manage /dev/md1 --add /dev/vdb
# mdadm --manage /dev/md1 --add /dev/vdc
\end{lstlisting}

\begin{terminaloutput}
\footnotesize\begin{verbatim}
mdadm: added /dev/vdb
mdadm: added /dev/vdc
\end{verbatim}
\end{terminaloutput}

Un cop afegits els discs de recanvi al RAID 1, podem comprovar l'estat del RAID 1 amb la comanda \texttt{cat /proc/mdstat}:

\begin{terminaloutput}
\footnotesize\begin{verbatim}
Personalities : [raid0] [raid1]
md1 : active raid1 vdc[3](S) vdb[2](S) vde[1] vdd[0]
      1046528 blocks super 1.2 [2/2] [UU]
unused devices: <none>
\end{verbatim}
\end{terminaloutput}

En aquesta sortida, podem veure que els discs \textbf{/dev/vdb} i \textbf{/dev/vdc} s'han afegit com a discs de recanvi al RAID 1. Això significa que si un dels discs actius falla, els discs de recanvi es posaran en marxa automàticament per mantenir la disponibilitat de les dades. Per exemple, si marquem el disc \textbf{/dev/vde} com a fallit:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm --manage --set-faulty /dev/md1 /dev/vde
\end{lstlisting}

\begin{terminaloutput}
\footnotesize\begin{verbatim}
mdadm: set /dev/vde faulty in /dev/md1
\end{verbatim}
\end{terminaloutput}

Podem comprovar l'estat del RAID 1 amb la comanda \texttt{cat /proc/mdstat}. Si ho feu ràpid podreu veure com el RAID 1 es reconstrueix amb el disc de recanvi \textbf{/dev/vdb}.

\begin{terminaloutput}
\footnotesize\begin{verbatim}
Personalities : [raid0] [raid1]
md1 : active raid1 vdc[3] vdb[2](S) vde[1](F) vdd[0]
      1046528 blocks super 1.2 [2/1] [U_]
      [=======>.............]  recovery = 38.2% (401280/1046528)
       finish=0.0min speed=401280K/sec
\end{verbatim}
\normalsize
\end{terminaloutput}

Si tornem a revisar l'estat del RAID 1 amb la comanda \texttt{cat /proc/mdstat}, veurem com el disc de recanvi \textbf{/dev/vdb} s'ha posat en marxa automàticament per mantenir la disponibilitat de les dades:

\begin{terminaloutput}
\footnotesize\begin{verbatim}
 Personalities : [raid0] [raid1]
md1 : active raid1 vdc[3] vdb[2](S) vde[1](F) vdd[0]
      1046528 blocks super 1.2 [2/2] [UU]
unused devices: <none>
\end{verbatim}
\end{terminaloutput}

\subsection{Pas 5: Muntar el RAID de forma
persistent}\label{pas-5-muntar-la-raid-de-forma-persistent}

Si reinicieu el sistema amb \texttt{reboot} observareu que el RAID ja no es troba muntat a \textbf{/mnt/raid1}. Per configurar el RAID de forma persistent necessitem editar \textbf{/etc/fstab}. Per fer-ho necessitem el UUID del RAID 1. Per obtenir el UUID del RAID 1, utilitza la comanda \texttt{blkid}:

\begin{lstlisting}[language=bash, numbers=none]
$ blkid | grep md1
\end{lstlisting}

\begin{terminaloutput}
\footnotesize\begin{verbatim}
/dev/md1: UUID="bbad3299-2b34-4748-88b6-1075efbd0f99" 
        BLOCK_SIZE="512" TYPE="xfs"
\end{verbatim}
\end{terminaloutput}

Ara podem afegir el RAID 1 al fitxer \textbf{/etc/fstab} per muntar-lo de forma persistent:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# echo "UUID=bbad3299-2b34-4748-88b6-1075efbd0f99 /mnt/raid1 xfs defaults 0 1" >> /etc/fstab
\end{lstlisting}

Un cop fet, podem desmuntar i tornar a muntar el RAID 1:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# umount /mnt/raid1
# mount -a
\end{lstlisting}


\section{Exemple 2: Configurant un Servidor}\label{exemple-2-configurant-un-servidor}

En aquest exemple, es planteja una situació en què disposem d'un servidor físic amb 2 SSDs i 4 HDDs. La configuració d'aquest servidor es planteja de manera que es pugui aprofitar al màxim les característiques i avantatges de cada tipus de disc. 

\begin{mdframed}[linewidth=2pt,linecolor=teal]
Una situació típica pot ser tenir 2 SSDs de 500GB per al sistema operatiu i 4 HDDs de 4TB per emmagatzemar dades. En aquest cas, es podria configurar un RAID 1 amb els dos SSDs per al sistema operatiu i un RAID 5 amb els quatre HDDs per emmagatzemar dades. Aquesta configuració permet aprofitar la velocitat i rendiment dels SSDs per al sistema operatiu, i la capacitat d'emmagatzematge dels HDDs per a les dades. Optimitzant el cost, ja que els SSDs són més cars que els HDDs a data d'escriptura d'aquest llibre.
\end{mdframed}

Els SSDs, gràcies a la seva alta velocitat i rendiment, són ideals per albergar el sistema operatiu. Per això, es proposa crear un RAID 1 amb els dos SSDs. Aquesta configuració proporciona una alta disponibilitat, ja que si un dels discs falla, l'altre pot continuar funcionant sense interrupcions. A més, el RAID 1 ofereix una lectura de dades ràpida, cosa que és beneficiosa per al sistema operatiu.

D'altra banda, els HDDs, tot i que són més lents que els SSDs, ofereixen una gran capacitat d'emmagatzematge a un cost relativament baix. Aquesta característica els fa ideals per emmagatzemar grans quantitats de dades. Per això, es proposa crear un RAID 5 amb els cinc HDDs. El RAID 5 ofereix una bona combinació de rendiment i protecció de dades, ja que utilitza la paritat per permetre la recuperació de dades en cas de fallada d'un disc.

\begin{info}
Aquests RAIDs es podrien configurar com a Hardware RAID si el servidor disposa d'un controlador RAID integrat. Acte seguit, es podria instal·lar el sistema operatiu en el RAID 1 i utilitzar el RAID 5 per emmagatzemar les dades.
\end{info}

\begin{warning}
No obstant això, utilitzar Hardware RAIDs implica tenir hardware específic i no es poden emular fàcilment. Per tant, instal·larem el sistema operatiu en una màquina virtual i després configurarem els RAIDs com a Software RAID.
\end{warning}

En aquest exemple, utilitzarem AlmaLinux com a sistema operatiu. Aquesta distribució és una bifurcació de CentOS i està dissenyada per ser una alternativa compatible amb Red Hat Enterprise Linux (RHEL). Per fer-ho crearem dos escenaris diferents:

\begin{enumerate}
        \item \textbf{Escenari 1}: Instal·larem el servidor i configurarem els RAIDs durant la instal·lació del sistema operatiu. 
        \item \textbf{Escenari 2}: Farem la migració del sistema operatiu a un RAID 1 i les dades a un RAID 5.
\end{enumerate}


\subsection{Escenari 1: Instal·lació d'un servidor}\label{escenari-1-instal·lació-del-sistema-operatiu}

En aquest escenari instal·larem el sistema operatiu i configurarem els RAIDs durant la instal·lació. Això ens permetrà tenir el sistema operatiu i els RAIDs configurats i preparats per a l'ús immediatament després de la instal·lació. A continuació es mostren els passos per configurar els RAIDs durant la instal·lació del sistema operatiu. 

\begin{enumerate}
        \item Creació d'una màquina virtual amb 6 discs virtuals. Els autors del llibre han utilitzat UTM per aquest propòsit. Els discs virtuals han estat configurats de 20GB pel Sistema Operatiu i 10GB per les dades.
        \item Els autors han utiltizat la imatge d'AlmaLinux 9.3 per aquest propòsit. Podeu descarregar la imatge d'AlmaLinux des del seu lloc web oficial.
        \item Instal·lació d'AlmaLinux. Per fer-ho, podeu utiltizar el particionament estandard. %, ja que encara no hem parlat de LVM.
El sistema de particions pot ser automàtic ja que després l'editarem per crear els RAIDs.
\end{enumerate}

Les figures \ref{fig:ex2_discs1} a \ref{fig:ex2_confirmacio} mostren un resum dels passos necessaris per la configuració del RAID 1 i del RAID 5 durant la instal·lació del sistema operatiu. %Aneu amb compte i seleccioneu els discs correctes per cada punt de muntatge. 

Tal com mostra la figura \ref{fig:ex2_discs2} seleccionareu tots els discs i marcareu la casella de \textbf{Personalitzar la taula de particions}. Acte seguit, seleccionareu \textbf{Partició estàndard} i clicareu a \textit{Feu click per crear-ho automàticament}. Això crearà una configuració inicial de partida que editarem de la següent manera:

\begin{itemize}
        \item Seleccionarem el primer disc (\textbf{/dev/vda}) i crearem:
        \begin{itemize}
                \item La partició (vda1): 600MB per al punt de muntatge \textit{/boot/efi}.
                \item La partició (vda2): 1GB per al punt de muntatge \textit{/boot}.
        \end{itemize}
        \item Seleccionarem el segon disc (\textbf{/dev/vdb}) i crearem:
        \begin{itemize}
                \item La partició (vdb2): 4GB per al punt de muntatge \textit{swap}.
        \end{itemize}
        \item Seleccionarem el primer (\textbf{/dev/vda} i el segon disc (\textbf{/dev/vdb}) i crearem:
        \begin{itemize}
                \item Un RAID 1 de tipus \textit{XFS} de 16GB per al punt de muntatge \textit{/}.
        \end{itemize}
        \item Seleccionarem el tercer disc (\textbf{/dev/vdc}), el quart disc (\textbf{/dev/vdd}), el cinquè disc (\textbf{/dev/vde}) i el sisè disc (\textbf{/dev/vdf}) i crearem:
        \begin{itemize}
                \item Un RAID 5 de tipus \textit{XFS} de 20GB per al punt de muntatge \textit{/home}.
        \end{itemize}  
\end{itemize}


\begin{figure}[!htb]
        \centering
        \includegraphics[width=\textwidth]{Exemple2/discs.png}
        \caption{Configuració del RAID 1}
        \label{fig:ex2_discs1}
\end{figure}
        
\begin{figure}[!htb]
        \centering
        \includegraphics[width=\textwidth]{Exemple2/seleccio_discs.png}
        \caption{Configuració del RAID 1}
        \label{fig:ex2_discs2}
\end{figure}

\begin{figure}[!htb]
        \centering
        \includegraphics[width=\textwidth]{Exemple2/boot.png}
        \caption{Configuració del \textbf{/boot}}
        \label{fig:ex2_boot}
\end{figure}

\begin{figure}[!htb]
        \centering
        \includegraphics[width=\textwidth]{Exemple2/efi.png}
        \caption{Configuració del \textbf{/boot/efi}}
        \label{fig:ex2_efi}
\end{figure}

\begin{figure}[!htb]
        \centering
        \includegraphics[width=\textwidth]{Exemple2/os.png}
        \caption{Configuració del RAID 1}
        \label{fig:ex2_os}
\end{figure}


\begin{figure}[!htb]
        \centering
        \includegraphics[width=\textwidth]{Exemple2/swap.png}
        \caption{Configuració del swap}
        \label{fig:ex2_swap}
\end{figure}

\begin{figure}[!htb]
        \centering
        \includegraphics[width=\textwidth]{Exemple2/home.png}
        \caption{Configuració del RAID 5}
        \label{fig:ex2_home}
\end{figure}

\begin{figure}[!htb]
        \centering
        \includegraphics[width=\textwidth]{Exemple2/confirmacio.png}
        \caption{Confirmació de la configuració dels discs}
        \label{fig:ex2_confirmacio}
\end{figure}

\begin{warning}
Les particions \textbf{/boot} i \textbf{/boot/efi} s'han configurat de manera independent perquè el sistema operatiu necessita que estiguin en particions separades. Aquestes particions són crucials per al procés d'arrencada del sistema operatiu. Per aquesta raó, s'han de crear en un dels discs que es faran servir per al RAID 1. Aquesta estratègia assegura que el sistema operatiu pugui accedir a aquestes particions de manera eficient durant el procés d'arrencada.
\end{warning}

Finalment, podeu testar la configuració acabant la instal·lació del sistema operatiu. Un cop finalitzada la instal·lació, podeu reiniciar el sistema i comprovar que els RAIDs s'han configurat correctament. La figura \ref{fig:ex2_final} mostra la sortida de la comanda \texttt{df -h} després de la instal·lació del sistema operatiu i l'arrencada del sistema. Es pot observar com s'han creat els RAIDs i s'han muntat correctament. Tenim \textbf{/dev/md127} muntat a \textbf{/} amb una mida de 16GB i \textbf{/dev/md126} muntat a \textbf{/home} amb una mida de 9,3 GB. També s'observa els raids 1 i 5 amb la comanda \texttt{cat /proc/mdstat} com actiu i amb els discs configurats de forma correcta.

\begin{figure}
        \centering
        \includegraphics[width=\textwidth]{Exemple2/final.png}
        \caption{Sortida de la comanda \texttt{df -h} i \texttt{cat /proc/mdstat} després de la instal·lació del sistema operatiu i arrancada del sistema.}
        \label{fig:ex2_final}
\end{figure}


\subsection{Escenari 2: Migració d'un servidor}\label{escenari-1-instal·lació-del-sistema-operatiu}

En aquest exemple, instal·larem el sistema operatiu en un disc i després migrarem el sistema operatiu a un RAID 1 format per dos discs diferents i també migrarem les dades a un RAID 5. Això ens permetrà migrar el sistema operatiu i les dades a RAIDs configurats de manera òptima sense haver de reinstal·lar el sistema operatiu. Els passos que seguirem són similars als de l'escenari anterior, però en aquest cas assumirem que fem el manteniment d'un servidor ja en funcionament.

Assumirem que aquest servidor en funcionament el tenim instal·lat en una màquina virtual amb el sistema operatiu AlmaLinux. Aquesta màquina virtual té un disc de 20GB (\textbf{/dev/vda}) i el sistema de particions estàndard. En aquest punt, tenim les següents particions al disc \texttt{/dev/vda}:

\begin{itemize}
        \item \texttt{/boot} (600 MB) (XFS)
        \item \texttt{/boot/efi} (1024 MB) (VFAT)
        \item \texttt{swap} (2 GB) (SWAP)
        \item \texttt{/} (16,41 GB) (XFS)
\end{itemize}
Un cop arrencada la màquina, si executem \texttt{lsblk}, hauríem de veure una sortida semblant a la següent:

\begin{terminaloutput}
\footnotesize\begin{verbatim}
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
sr0     11:0    1 1024M  0 rom
vda    253:0    0   20G  0 disk
├─vda1 253:1    0  600M  0 part /boot/efi
├─vda2 253:2    0    1G  0 part /boot
├─vda3 253:3    0    2G  0 part [SWAP]
└─vda4 253:4    0 16,4G  0 part /
\end{verbatim}
\end{terminaloutput}

\begin{mdframed}[linewidth=2pt,linecolor=teal]
%En aquest escenari us plantejo solucionar un problema que pot aparèixer en la configuració del primer exemple.
\textbf{Què passaria si la partició \texttt{/boot} falla?} \textit{En aquest cas, no podríem arrencar el sistema operatiu. No ens serviria de res el RAID 1 configurat de les particions del sistema operatiu.}
\end{mdframed}


Per això, en aquest exemple, es planteja una solució més robusta. Crearem 4 RAIDs de nivell 1 amb els discs \texttt{/dev/vdb} i \texttt{/dev/vdc}. Aquests RAIDs seran:

\begin{enumerate}
        \item RAID 1 per \texttt{/boot} i \texttt{/boot/efi}:  La partició /boot conté els fitxers necessaris per arrencar el sistema operatiu, mentre que /boot/efi és essencial per als sistemes UEFI. Amb un RAID 1 per a aquestes particions, assegurem que el sistema pugui arrencar fins i tot si un dels discs falla. Per tant, en cas de fallada d'una partició d'arrancada, el sistema operatiu encara es pot arrencar.
        \item RAID 1 per \texttt{swap}: La memòria swap és crítica per al rendiment del sistema. Amb un RAID 1 per a la memòria swap, evitem la pèrdua de dades i mantenim la capacitat de gestió de la memòria virtual. Per tant, en cas de fallada d'una partició de swap, el sistema operatiu encara pot gestionar la memòria virtual.
        \item RAID 1 per \texttt{/}: La partició / conté el sistema operatiu i les aplicacions. Amb un RAID 1 aquí, garantim la disponibilitat i la integritat del sistema. Per tant, en cas de fallada d'una partició del sistema operatiu, el sistema encara es pot arrencar.
\end{enumerate}

\begin{warning}
Durant la configuració, estarem editant els fitxers \texttt{/etc/fstab}, així com muntant i desmuntant particions. Durant aquest procés, el sistema us suggerirà que utilitzeu la comanda \texttt{systemctl-reload} per aplicar els canvis. No cal que feu cas d’aquesta indicació; simplement continueu amb la instal·lació. Un cop finalitzada, farem un reinici del sistema i tot es configurarà de manera correcta.
\end{warning}

El primer pas serà particionar els discs \texttt{/dev/vdb} i \texttt{/dev/vdc} amb taules del tipus GPT\footnote{Les taules de particions del tipus  \texttt{GPT (GUID Partition Table)} permeten l'ús de discs d'un tamany molt superior als que són compatibles amb l'antic estàndard MBR.}. Particionant el disc  \texttt{/dev/vdb}:

\begin{enumerate}
        \item /boot/efi:
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# echo -e "g\nn\np\n1\n\n+600M\nt\n29\nw" | fdisk /dev/vdb
\end{lstlisting}
        \item /boot:
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# echo -e "n\np\n2\n\n+1G\nt\n2\n29\nw" | fdisk /dev/vdb
\end{lstlisting}
        \item swap:
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
 # echo -e "n\np\n3\n\n+2G\nt\n3\n29\nw" | fdisk /dev/vdb
\end{lstlisting}
        \item /:
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# echo -e "n\np\n4\n\n+16G\nt\n4\n29\nw" | fdisk /dev/vdb
\end{lstlisting}
\end{enumerate}

Explicació de la comanda\texttt{\# echo -e ''g\textbackslash{}nn\textbackslash{}np\textbackslash{}n1\textbackslash{}n\textbackslash{}n+600M\textbackslash{}nt\textbackslash{}n29\textbackslash{}nw'' | fdisk /dev/vdb}:
\begin{description}
\item[g:] Canvia el tipus de taula de particions a GPT.
\item[n:] Crea una nova partició.
\item[p:] Mostra la taula de particions.
\item[1:] Indica que es crearà la primera partició.
\item[\textbackslash{}n:] Un salt de línia en blanc, el que significa que acceptarà els valors predeterminats per a la partició (mida máxima disponible).
\item[+600M:] Especifica la mida de la partició com 600 MB.
\item[t:] Canvia el tipus de partició.
\item[29:] Indica el tipus de partició com a 29 (per a una partició de tipus Linux RAID).
\item[w:] Escriu els canvis realitzats a la taula de particions i surt de fdisk.
\item[| fdisk /dev/vdb:] El símbol | és un "pipe", que pren la sortida de la comanda anterior i la passa com a entrada a la comanda fdisk. /dev/vdb és el dispositiu de disc en el qual es realitzaran les operacions de particionament.
\end{description}


Un cop creada la taula de particions en  \texttt{/dev/vdb}, heu de repetir aquests passos per al disc \texttt{/dev/vdc}.
Si executem \texttt{lsblk}, hauríem de veure una sortida semblant a la següent:

\begin{terminaloutput}
\footnotesize\begin{verbatim}
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
sr0     11:0    1 1024M  0 rom
vda    253:0    0   20G  0 disk
|-vda1 253:1    0  600M  0 part /boot/efi
|-vda1 253:1    0  600M  0 part /boot/efi
|-vda2 253:2    0    1G  0 part /boot
|-vda3 253:3    0    2G  0 part [SWAP]
|-vda4 253:4    0 16,4G  0 part /
vdb    253:16   0   20G  0 disk
|-vdb1 253:17   0  600M  0 part
|-vdb2 253:18   0    1G  0 part
|-vdb3 253:19   0    2G  0 part
|-vdb4 253:20   0   16G  0 part
vdc    253:32   0   20G  0 disk
|-vdc1 253:33   0  600M  0 part
|-vdc2 253:34   0    1G  0 part
|-vdc4 253:36   0   16G  0 part
\end{verbatim}
\end{terminaloutput}
                
Un cop creades les particions, començarem pel primer RAID 1 per a la partició \texttt{/boot/efi}. Per fer-ho, segueix els passos següents del script:

\begin{enumerate}
        \item Crear un RAID 1 per a la partició \texttt{/boot/efi} amb els discs \texttt{/dev/vdb1} i \texttt{/dev/vdc1}.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm --create /dev/md0 --level=1 --raid-devices=2 --metadata=1.0 /dev/vdb1 /dev/vdc1
\end{lstlisting}
        \item Crear un sistema de fitxers FAT32 a la partició RAID 1 per a la partició \texttt{/boot/efi}.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mkfs.vfat /dev/md0
\end{lstlisting}
        \item Copiar els fitxers de la partició \texttt{/boot/efi} a la partició RAID 1 amb la comanda \texttt{rsync}.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mkdir /tmp/raid1
# mount /dev/md0 /tmp/raid1
# rsync -avx /boot/efi/ /tmp/raid1
\end{lstlisting}
        \item Desmuntar la partició RAID 1.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# umount /tmp/raid1
\end{lstlisting}
        \item Seleccionar el UUID de la partició RAID 1.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# EFI_RAID_UUID=$(blkid -s UUID -o value /dev/md0)
\end{lstlisting}
        \item Actualitzar el fitxer \texttt{/etc/fstab} amb el UUID de la partició RAID 1 per a la partició \texttt{/boot/efi}.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# CURRENT_BOOT_UUID=$(blkid -s UUID -o value /dev/vda1)
# sed -i "s|UUID=$CURRENT_BOOT_UUID|UUID=$EFI_RAID_UUID|" /etc/fstab
\end{lstlisting}
\end{enumerate}

\begin{warning}
En aquest punt, heu de tenir en compte que la partició \texttt{/boot/efi} és una partició EFI, que requereix un sistema de fitxers FAT32. Per tant, heu de crear un sistema de fitxers FAT32 a la partició RAID 1 per a la partició \texttt{/boot/efi}. A més a més, les particions amb bootloaders necessiten ser configurades amb metadata 1.0. Això és important perquè els bootloaders EFI no us funcionaran amb metadata superiors a 1.0.
\end{warning}

A continuació crearem el RAID 1 per a la partició \texttt{/boot}. Per fer-ho, seguiu els passos següents (molt similars als anteriors):

\begin{enumerate}
        \item Crear un RAID 1 per a la partició \texttt{/boot} amb els discs \texttt{/dev/vdb2} i \texttt{/dev/vdc2}.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm --create /dev/md1 --level=1 --raid-devices=2 --metadata=1.0 /dev/vdb2 /dev/vdc2
\end{lstlisting}
        \item Crear un sistema de fitxers XFS a la partició RAID 1 per a la partició \texttt{/boot}.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mkfs.xfs /dev/md1
\end{lstlisting}
        \item Copiar els fitxers de la partició \texttt{/boot} a la partició RAID 1 amb la comanda \texttt{rsync}.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mkdir /tmp/raid2
# mount /dev/md1 /tmp/raid2
# rsync -avx /boot/ /tmp/raid2
\end{lstlisting}
        \item Desmuntar la partició RAID 1.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# umount /tmp/raid2
\end{lstlisting}
        \item Seleccionar el UUID de la partició RAID 1.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# BOOT_RAID_UUID=$(blkid -s UUID -o value /dev/md1)
\end{lstlisting}
        \item Actualitzar el fitxer \texttt{/etc/fstab} amb el UUID de la partició RAID 1 per a la partició \texttt{/boot}.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# CURRENT_BOOT_UUID=$(blkid -s UUID -o value /dev/vda2)
# sed -i "s|UUID=$CURRENT_BOOT_UUID|UUID=$BOOT_RAID_UUID|" /etc/fstab
\end{lstlisting}
\end{enumerate}

Un cop configurades les particions \texttt{/boot} i \texttt{/boot/efi}, crearem el RAID 1 per a la partició \texttt{swap}. Per fer-ho, seguiu els passos següents:

\begin{enumerate}
        \item Crear un RAID 1 per a la partició \texttt{swap} amb els discs \texttt{/dev/vdb3} i \texttt{/dev/vdc3}.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm --create /dev/md2 --level=1 --raid-devices=2  /dev/vdb3 /dev/vdc3
\end{lstlisting}
        \item Crear un sistema de swap a la partició RAID 1 per a la partició \texttt{swap}.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mkswap /dev/md2
\end{lstlisting}
        \item Activar la partició de swap.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# swapon /dev/md2
\end{lstlisting}
        \item Seleccionar el UUID de la partició RAID 1.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# SWAP_RAID_UUID=$(blkid -s UUID -o value /dev/md2)
\end{lstlisting}
        \item Actualitzar el fitxer \texttt{/etc/fstab} amb el UUID de la partició RAID 1 per a la partició \texttt{swap}.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# CURRENT_SWAP_UUID=$(blkid -s UUID -o value /dev/vda3)
# sed -i "s|UUID=$CURRENT_SWAP_UUID|UUID=$SWAP_RAID_UUID|" /etc/fstab
\end{lstlisting}
        \item Comprovar que la partició de swap s'ha activat correctament.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# swapon --show
\end{lstlisting}
\end{enumerate}

\begin{info}
En aquest punt, heu de tenir en compte que la partició de swap no necessita un sistema de fitxers. En lloc d'això, heu de crear un sistema de swap a la partició RAID 1 per a la partició de swap. Amb la comanda \texttt{mkswap}, podeu crear un sistema de swap, amb la comanda \texttt{swapon} podeu activar la partició de swap i amb la comanda \texttt{swapon --show} podeu comprovar que la partició de swap s'ha activat correctament.
\end{info}

Finalment, crearem el nostre darrer RAID 1 per a la partició \texttt{/}. Per fer-ho, seguiu els passos següents:

\begin{enumerate}
        \item Crear un RAID 1 per a la partició \texttt{/} amb els discs \texttt{/dev/vdb4} i \texttt{/dev/vdc4}.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm --create /dev/md3 --level=1 --raid-devices=2 /dev/vdb4 /dev/vdc4
\end{lstlisting}
        \item Crear un sistema de fitxers XFS a la partició del RAID 1 per a la partició \texttt{/} i muntar-la al directori \texttt{/mnt}.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mkfs.xfs /dev/md3
# mount /dev/md3 /mnt
\end{lstlisting}
        \item Copiar els fitxers de la partició \texttt{/} a la partició del RAID 1 amb la comanda \texttt{cp}.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# cp -ax / /mnt
\end{lstlisting}
        \item Desmuntar la partició del RAID 1.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# umount /mnt
\end{lstlisting}
        \item Seleccionar el UUID de la partició del RAID 1.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# ROOT_RAID_UUID=$(blkid -s UUID -o value /dev/md3)
\end{lstlisting}
        \item Actualitzar el fitxer \texttt{/etc/fstab} amb el UUID de la partició del RAID 1 per a la partició \texttt{/}.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# CURRENT_ROOT_UUID=$(blkid -s UUID -o value /dev/vda4)
# sed -i "s|UUID=$CURRENT_ROOT_UUID|UUID=$ROOT_RAID_UUID|" /etc/fstab
\end{lstlisting}
\end{enumerate}

\begin{info}
Observeu que en aquest cas, utilitzem la comanda \texttt{cp -ax} per copiar els fitxers de la partició \texttt{/} a la partició del RAID 1 per a la partició \texttt{/}. Aquesta comanda copia els fitxers de manera recursiva i preserva els enllaços simbòlics, els permisos, els propietaris i les dates de modificació dels fitxers. Això és important per garantir que el sistema operatiu es copia correctament a la partició del RAID 1 per a la partició \texttt{/}. També es podria fer amb \texttt{rsync}.
\end{info}

Un cop configurats tots els raids, podeu comprovar l'estat dels raids amb la comanda \texttt{cat /proc/mdstat}. Això us mostrarà l'estat dels raids i els discs que s'han afegit correctament. Un altra comanda que us pot ser útil és \texttt{mdadm --detail /dev/mdX} on \texttt{X} és el número de raid. 

\begin{warning}
En aquest punt, si no fem res més, els noms /dev/mdX no seran persistents i es perdran en el reinici del sistema. Per això, heu de configurar els noms de dispositius persistents per als raids. Observeu, el exemple anterior on \textbf{md0} i \textbf{md1} s'han transformat després del reinici en \textbf{md127} i \textbf{md126}.
\end{warning}

Per fer els noms de dispositius persistents, heu de crear un directori \texttt{/etc/mdadm} i un fitxer \texttt{mdadm.conf} amb la configuració dels raids. 

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mkdir /etc/mdadm
# mdadm --detail --scan > /etc/mdadm/mdadm.conf
\end{lstlisting}

\begin{warning}
Aquest fitxer \texttt{mdadm.conf} es troba al sistema operatiu que posarem com a \textit{deprecated} igual que l'última versió del \texttt{/etc/fstab}. Per tant:
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mount /dev/md3 /mnt
# mkdir /mnt/etc/mdadm
# cp /etc/mdadm/mdadm.conf /mnt/etc/mdadm/mdadm.conf
# cp /etc/fstab /mnt/etc/fstab
\end{lstlisting}
\end{warning}

Ara que ja tenim els RAIDs configurats i els noms de dispositius persistents, podem reiniciar el sistema i comprovar que els RAIDs s'han configurat correctament. Si ho feu, observareu que tot el sistema operatiu s'ha traslladat als RAIDs configurats. Però, la partició \texttt{/} no s'ha traslladat a RAID 1 i encara es munta \textbf{/dev/vd4}. Això és per que el grub encara està configurat per carregar el sistema operatiu des de la partició \texttt{/dev/vda4}. 

Per canviar això, heu de configurar el grub per carregar el sistema operatiu des de RAID 1. Per fer-ho, heu de modificar el fitxer \texttt{/etc/default/grub}. Editeu aquest fitxer semblant a la següent configuració substituint \texttt{<UUID>} pel UUID de RAID 1:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# vi /etc/default/grub
GRUB_TIMEOUT=5
GRUB_DISTRIBUTOR="$(sed 's, release .*$,,g' /etc/system-release)"
GRUB_DEFAULT=saved
GRUB_DISABLE_SUBMENU=true
GRUB_TERMINAL_OUTPUT="console"
GRUB_CMDLINE_LINUX="root=UUID=<UUID> rd.auto crashkernel=1G-4G:256M,4G-64G:320M,64G-:576M"
GRUB_DISABLE_RECOVERY="true"
GRUB_ENABLE_BLSCFG=false
GRUB_CMDLINE_LINUX_DEFAULT=""
# cp /etc/default/grub /mnt/etc/default/grub
\end{lstlisting}

Una vegada completat aquest pas, procedirem a instal·lar el grub en cada un dels dispositius que formen part de RAID 1. Per a aquesta tasca, farem ús de la comanda \texttt{efibootmgr}. Aquesta eina ens permet gestionar les entrades del bootloader EFI en un entorn amb Secure Boot activat.

En cas que no disposis de Secure Boot, es pot recórrer a la comanda \texttt{grub2-install}. No obstant això, cal destacar que, en l'actualitat, la majoria de servidors operen amb Secure Boot activat. A més, no es recomana la seva desactivació, ja que Secure Boot proporciona una capa de seguretat addicional que reforça la protecció del sistema.

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# efibootmgr --create --disk /dev/vdb --part 1 --label "almalinux-mirror-01" --loader "\EFI\almalinux\shimaa64.efi"
# efibootmgr --create --disk /dev/vdc --part 1 --label "almalinux-mirror-02" --loader "\EFI\almalinux\shimaa64.efi"
\end{lstlisting}

\begin{info}
Utilitzem el loader \texttt{shimaa64.efi} perquè és el bootloader que s'utilitza amb Secure Boot. Aquest bootloader permet carregar el kernel i els mòduls de signatura per aconseguir que el sistema operatiu es carregui correctament amb Secure Boot activat.
\end{info}

Un cop completat aquest pas, podem reconfigurar el grub2 a partir de la configuració (fitxer \texttt{/etc/default/grub}) que hem fet anteriorment. Per fer-ho, utilitzem la comanda \texttt{grub2-mkconfig}. A més a més, actualitzarem la imatge initramfs amb la comanda \texttt{dracut} per assegurar-nos que el sistema operatiu es carrega correctament des de RAID 1:

\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# grub2-mkconfig -o /boot/efi/EFI/almalinux/grub.cfg
# dracut -f
\end{lstlisting}

Finalment, podem eliminar el disc \texttt{/dev/vda} i reiniciar el sistema. Si tot ha anat bé, el sistema s'hauria de carregar correctament des de RAID 1.

\begin{terminaloutput}
\footnotesize\begin{verbatim}
NAME    MAJ:MIN RM    SIZE RO TYPE  MOUNTPOINTS
sr0      11:0    1   1024M  0 rom
vda     253:0    0     20G  0 disk
├─vda1  253:1    0    600M  0 part
├─vda2  253:2    0      1G  0 part
├─vda3  253:3    0      2G  0 part
└─vda4  253:4    0   16,4G  0 part
vdb     253:16   0     20G  0 disk
├─vdb1  253:17   0    600M  0 part
│ └─md0   9:0    0  599,9M  0 raid1 /boot/efi
├─vdb2  253:18   0      1G  0 part
│ └─md1   9:1    0 1023,9M  0 raid1 /boot
├─vdb3  253:19   0      2G  0 part
│ └─md2   9:2    0      2G  0 raid1 [SWAP]
└─vdb4  253:20   0     16G  0 part
  └─md3   9:3    0     16G  0 raid1 /
vdc     253:32   0     20G  0 disk
├─vdc1  253:33   0    600M  0 part
│ └─md0   9:0    0  599,9M  0 raid1 /boot/efi
├─vdc2  253:34   0      1G  0 part
│ └─md1   9:1    0 1023,9M  0 raid1 /boot
├─vdc3  253:35   0      2G  0 part
│ └─md2   9:2    0      2G  0 raid1 [SWAP]
└─vdc4  253:36   0     16G  0 part
  └─md3   9:3    0     16G  0 raid1 /
\end{verbatim}
\end{terminaloutput}

En aquest punt, ja podem començar la migració de les dades al RAID 5. Per fer-ho, seguiu els passos següents:

\begin{enumerate}
        \item Crear 4 discs virtuals amb 10GB de capacitat cadascun.
        \item Crear una taula de particions GPT en els discs virtuals amb una partició de 10GB.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# echo -e "g\nn\n1\n\n+10G\nw" | fdisk /dev/vdd
# echo -e "g\nn\n1\n\n+10G\nw" | fdisk /dev/vde
# echo -e "g\nn\n1\n\n+10G\nw" | fdisk /dev/vdf
# echo -e "g\nn\n1\n\n+10G\nw" | fdisk /dev/vdg
\end{lstlisting}
        \item Crear un RAID 5 amb els 4 discs virtuals.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mdadm --create /dev/md4 --level=5 --raid-devices=4 /dev/vdd1 /dev/vde1 /dev/vdf1 /dev/vdg1
\end{lstlisting}
        \item Crear un sistema de fitxers XFS a la partició del RAID 5.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mkfs.xfs /dev/md2
\end{lstlisting}
        \item Muntar la partició del RAID 5 al directori \texttt{/mnt/raid5}.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# mkdir /mnt/raid5
# mount /dev/md2 /mnt/raid5
\end{lstlisting}
        \item Copiar els fitxers de la partició \texttt{/home} a la partició del RAID 5 amb la comanda \texttt{rsync}.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# rsync -avx /home/ /mnt/raid5
\end{lstlisting}
        \item Desmuntar la partició del RAID 5.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# umount /mnt/raid5
\end{lstlisting}
        \item Modificar el fitxer \texttt{/etc/fstab} per muntar la partició del RAID 5 de forma persistent.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# RAID5_UUID=$(blkid -s UUID -o value /dev/md2)
# echo "UUID=$RAID5_UUID /home xfs defaults 0 0" >> /etc/fstab
\end{lstlisting}
        \item Tornar a muntar les particions.
\begin{lstlisting}[language=bash, numbers=none, commentstyle=\color{black}]
# systemctl daemon-reload
# mount -a
\end{lstlisting}
\end{enumerate}

Ja tenim el sistema operatiu i les dades migrades als RAIDs configurats. Ara, podeu comprovar l'estat dels RAIDs amb la comanda \texttt{cat /proc/mdstat} i la sortida de la comanda \texttt{df -h} per veure les particions muntades. 




